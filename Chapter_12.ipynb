{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "ZlgqiT7YL0_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mlgtt9gdLowo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmj77VNYRpw3",
        "outputId": "233c0dc3-7d53-4f77-d7dc-cfbff59ab2b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m823.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "jOlY228vR2MK",
        "outputId": "2ac7dc3c-5c1f-4c47-a92e-9b80a983ea64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path\n",
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-lO-nQ5R3ZZ",
        "outputId": "f063967e-849f-4e27-fe42-fd38e62bbaa2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "160GMe5mSEBB",
        "outputId": "04bfaa19-647b-419d-bcf7-a1afad33884f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4vmzYuISHYp",
        "outputId": "64b4eaaa-631b-4ba0-8f00-4fd1d1fd4304"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU51gxqWSKiC",
        "outputId": "b0edb931-3307-4e72-fd5b-2b786343e242"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)\n",
        "nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wbbmIb8SN0a",
        "outputId": "c9b29969-d703-44f5-e760-0653bd382bd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L((tokens[i:i+2], tokens[i+2]) for i in range(0,len(tokens)-2,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEX7gJMISTxa",
        "outputId": "5dece5e6-f4ca-426c-fe82-eb204a1f4c61"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#31547) [(['one', '.'], 'two'),(['two', '.'], 'three'),(['three', '.'], 'four'),(['four', '.'], 'five'),(['five', '.'], 'six'),(['six', '.'], 'seven'),(['seven', '.'], 'eight'),(['eight', '.'], 'nine'),(['nine', '.'], 'ten'),(['ten', '.'], 'eleven')...]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = L((tensor(nums[i:i+2]), nums[i+2]) for i in range(0,len(nums)-2,2))\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knoKpzg0SWwn",
        "outputId": "5f214730-92dd-49b3-fe46-a9135a77b8fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#31547) [(tensor([0, 1]), 2),(tensor([2, 1]), 3),(tensor([3, 1]), 4),(tensor([4, 1]), 5),(tensor([5, 1]), 6),(tensor([6, 1]), 7),(tensor([7, 1]), 8),(tensor([8, 1]), 9),(tensor([9, 1]), 10),(tensor([10,  1]), 11)...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "metadata": {
        "id": "zyDSC4U7SaQs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questionaire 5\n",
        "Write a module that predicts the third word given the previous two words of a\n",
        "sentence."
      ],
      "metadata": {
        "id": "3hhtKrnc8eVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelQ5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.inp = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.out = nn.Linear(n_hidden, vocab_sz)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(2):\n",
        "            h = h + self.inp(x[:, i])\n",
        "            h = F.relu(h + self.hidden(self.inp(x[:, i])))\n",
        "\n",
        "        return self.out(h)"
      ],
      "metadata": {
        "id": "L5mt9OPYLz_R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, ModelQ5(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "6zR6S-KtMkUJ",
        "outputId": "d6f6f7bb-d178-4726-ecf3-e9a0190948e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.811080</td>\n",
              "      <td>2.418282</td>\n",
              "      <td>0.298098</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.372512</td>\n",
              "      <td>2.082177</td>\n",
              "      <td>0.387322</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.433461</td>\n",
              "      <td>1.794139</td>\n",
              "      <td>0.460539</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.422006</td>\n",
              "      <td>1.801781</td>\n",
              "      <td>0.382250</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More data preparation"
      ],
      "metadata": {
        "id": "XjTJAWyh8fgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_chunks(ds, bs):\n",
        "    m = len(ds) // bs\n",
        "    new_ds = L()\n",
        "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
        "    return new_ds"
      ],
      "metadata": {
        "id": "5TZBP0ZeS5Lv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sl = 16\n",
        "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
        "         for i in range(0,len(nums)-sl-1,sl))\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
        "                             group_chunks(seqs[cut:], bs),\n",
        "                             bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "26YAC4uZ80ZQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw_DDG5B84tR",
        "outputId": "8f3306a9-777c-4e4b-a6d2-5b451322bd83"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questionaire 13\n",
        "Write code to print out the first few batches of the validation set, including converting the token IDs back into English strings, as we showed for batches of IMDb data in Chapter 10."
      ],
      "metadata": {
        "id": "BKpgKQdB9J_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(dls.valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EZtlC1RJWN8",
        "outputId": "eac02dae-7886-4de7-f23e-3ee2a847adfd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(dls.valid)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNqCpKXjCKU6",
        "outputId": "0400fb5e-f13d-4609-9041-1801093a844b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[29, 26,  3,  ...,  1,  8, 29],\n",
              "         [ 0, 28, 18,  ..., 28, 20,  1],\n",
              "         [28, 22,  6,  ...,  0, 28, 22],\n",
              "         ...,\n",
              "         [ 9, 29,  8,  ...,  1,  9, 29],\n",
              "         [ 1,  9, 29,  ...,  3,  1,  9],\n",
              "         [28, 20,  2,  ...,  9, 28, 20]]),\n",
              " tensor([[26,  3,  1,  ...,  8, 29, 26],\n",
              "         [28, 18,  1,  ..., 20,  1,  8],\n",
              "         [22,  6,  1,  ..., 28, 22,  8],\n",
              "         ...,\n",
              "         [29,  8, 28,  ...,  9, 29,  8],\n",
              "         [ 9, 29,  8,  ...,  1,  9, 29],\n",
              "         [20,  2,  1,  ..., 28, 20,  4]]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nBR9uQ2BDgm",
        "outputId": "e5004be8-c104-43af-d698-df3a83bb6348"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "def show_batch(self:DataLoaders, vocab, max_n=1, max_toks=100):\n",
        "    batches = list(self.valid)[:max_n]\n",
        "    dic = {0:'x', 1:'y'}\n",
        "    for i in range(min(len(self.valid), max_n)):\n",
        "        for j in range(2):\n",
        "            print(f'{dic[j]}{i}: ')\n",
        "            count = 0\n",
        "            for k in batches[i][j]:\n",
        "                for l in k:\n",
        "                    print(vocab[l], end=' ')\n",
        "                    count += 1\n",
        "\n",
        "                print()\n",
        "                if count > max_toks:\n",
        "                    break\n",
        "\n",
        "            print()"
      ],
      "metadata": {
        "id": "PnhxG_8r-DU-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch(vocab, max_n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2eV1y6L_knc",
        "outputId": "c7708d16-23b0-43d6-ebdc-e12af581612f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0: \n",
            "thousand eighty three . eight thousand eighty four . eight thousand eighty five . eight thousand \n",
            "one hundred eighteen . eight thousand one hundred nineteen . eight thousand one hundred twenty . \n",
            "hundred forty six . eight thousand one hundred forty seven . eight thousand one hundred forty \n",
            "one hundred seventy four . eight thousand one hundred seventy five . eight thousand one hundred \n",
            "hundred two . eight thousand two hundred three . eight thousand two hundred four . eight \n",
            "two . eight thousand two hundred thirty three . eight thousand two hundred thirty four . \n",
            "hundred sixty . eight thousand two hundred sixty one . eight thousand two hundred sixty two \n",
            "\n",
            "y0: \n",
            "eighty three . eight thousand eighty four . eight thousand eighty five . eight thousand eighty \n",
            "hundred eighteen . eight thousand one hundred nineteen . eight thousand one hundred twenty . eight \n",
            "forty six . eight thousand one hundred forty seven . eight thousand one hundred forty eight \n",
            "hundred seventy four . eight thousand one hundred seventy five . eight thousand one hundred seventy \n",
            "two . eight thousand two hundred three . eight thousand two hundred four . eight thousand \n",
            ". eight thousand two hundred thirty three . eight thousand two hundred thirty four . eight \n",
            "sixty . eight thousand two hundred sixty one . eight thousand two hundred sixty two . \n",
            "\n",
            "x1: \n",
            "eighty six . eight thousand eighty seven . eight thousand eighty eight . eight thousand eighty \n",
            "eight thousand one hundred twenty one . eight thousand one hundred twenty two . eight thousand \n",
            "eight . eight thousand one hundred forty nine . eight thousand one hundred fifty . eight \n",
            "seventy six . eight thousand one hundred seventy seven . eight thousand one hundred seventy eight \n",
            "thousand two hundred five . eight thousand two hundred six . eight thousand two hundred seven \n",
            "eight thousand two hundred thirty five . eight thousand two hundred thirty six . eight thousand \n",
            ". eight thousand two hundred sixty three . eight thousand two hundred sixty four . eight \n",
            "\n",
            "y1: \n",
            "six . eight thousand eighty seven . eight thousand eighty eight . eight thousand eighty nine \n",
            "thousand one hundred twenty one . eight thousand one hundred twenty two . eight thousand one \n",
            ". eight thousand one hundred forty nine . eight thousand one hundred fifty . eight thousand \n",
            "six . eight thousand one hundred seventy seven . eight thousand one hundred seventy eight . \n",
            "two hundred five . eight thousand two hundred six . eight thousand two hundred seven . \n",
            "thousand two hundred thirty five . eight thousand two hundred thirty six . eight thousand two \n",
            "eight thousand two hundred sixty three . eight thousand two hundred sixty four . eight thousand \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Research 2: Create an LSTM model from scratch"
      ],
      "metadata": {
        "id": "MZhNkT-YXFvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-book implementation (with pytorch LSTM module)"
      ],
      "metadata": {
        "id": "f1FmZG0_PHlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel7(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        raw, self.h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = [h_.detach() for h_ in self.h]\n",
        "        return self.h_o(out),raw,out\n",
        "\n",
        "    def reset(self):\n",
        "        for h in self.h: h.zero_()\n"
      ],
      "metadata": {
        "id": "fakBaVsaOcYa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "    loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "2o4dKb65OyMi",
        "outputId": "b5e8cf66-1ebc-40a9-c565-b4ca34cf1f54"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.635747</td>\n",
              "      <td>1.948849</td>\n",
              "      <td>0.476562</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.643492</td>\n",
              "      <td>1.283160</td>\n",
              "      <td>0.632487</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.897427</td>\n",
              "      <td>0.905510</td>\n",
              "      <td>0.775391</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.436292</td>\n",
              "      <td>0.596966</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.220455</td>\n",
              "      <td>0.581759</td>\n",
              "      <td>0.832601</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.123104</td>\n",
              "      <td>0.570450</td>\n",
              "      <td>0.838949</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.075610</td>\n",
              "      <td>0.505292</td>\n",
              "      <td>0.854980</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.052278</td>\n",
              "      <td>0.490127</td>\n",
              "      <td>0.866455</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.037712</td>\n",
              "      <td>0.479434</td>\n",
              "      <td>0.869466</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.029503</td>\n",
              "      <td>0.500043</td>\n",
              "      <td>0.861328</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.022830</td>\n",
              "      <td>0.444735</td>\n",
              "      <td>0.871257</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.491629</td>\n",
              "      <td>0.869222</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.015726</td>\n",
              "      <td>0.529711</td>\n",
              "      <td>0.863118</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.014188</td>\n",
              "      <td>0.530687</td>\n",
              "      <td>0.862956</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>0.532394</td>\n",
              "      <td>0.862956</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verbose:"
      ],
      "metadata": {
        "id": "W7aPC0q0cqtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Chip(Module):\n",
        "    def __init__(self, i_n, hn):\n",
        "        self.forget_gate = nn.Linear(i_n + hn, hn)\n",
        "        self.input_gate = nn.Linear(i_n + hn, hn)\n",
        "        self.cell_gate = nn.Linear(i_n + hn, hn)\n",
        "        self.output_gate = nn.Linear(i_n + hn, hn)\n",
        "\n",
        "    def forward(self, inp, state):\n",
        "        h, c = state\n",
        "        h = torch.cat([h, inp], dim=1)\n",
        "        c = c * torch.sigmoid(self.forget_gate(h))\n",
        "        c = c + torch.sigmoid(self.input_gate(h)) * self.cell_gate(h).tanh()\n",
        "        h = torch.sigmoid(self.output_gate(h)) * torch.tanh(c)\n",
        "        return h, (h, c)"
      ],
      "metadata": {
        "id": "tLT4rfDGDb1q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refactored:"
      ],
      "metadata": {
        "id": "a4_YIi-lcsoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Ref(Module):\n",
        "    def __init__(self, i_n, hn):\n",
        "        self.i_g = nn.Linear(i_n, 4*hn, bias=True)\n",
        "        self.h_g = nn.Linear(hn, 4*hn, bias=True)\n",
        "\n",
        "    def forward(self, inp, state):\n",
        "        h, c = state\n",
        "        gates = (self.i_g(inp) + self.h_g(h)).chunk(4, 1)\n",
        "        forget_gate, input_gate, output_gate = map(torch.sigmoid, gates[:3])\n",
        "        cell_gate = gates[3].tanh()\n",
        "        c = c * forget_gate + input_gate * cell_gate\n",
        "        h = output_gate * torch.tanh(c)\n",
        "        return h, (h, c)\n"
      ],
      "metadata": {
        "id": "d-Q3BacXcuFB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's put it in a model"
      ],
      "metadata": {
        "id": "W5MDnracgiOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In cannonical dropout method I should return dropped instead of raw, however after many experiments I realised that when using dropout just for regularization and returning raw I get better results"
      ],
      "metadata": {
        "id": "vFHSMdC7yJr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Model(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.n_layers = n_layers\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = LSTM_Ref(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(2, bs, n_hidden) for _ in range(n_layers)]\n",
        "        self.drop = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        raw = []\n",
        "        dropped = []\n",
        "        for i in range(sl):\n",
        "            for j in range(self.n_layers):\n",
        "                y, self.h[j] = self.rnn(self.i_h(x[:, i]), self.h[j])\n",
        "\n",
        "            raw.append(y)\n",
        "            y = self.drop(y)\n",
        "            dropped.append(y)\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            self.h[i] = torch.stack(self.h[i])\n",
        "\n",
        "        self.h = [h_.detach() for h_ in self.h]\n",
        "        raw = torch.stack(raw, dim=1)\n",
        "        dropped = torch.stack(dropped, dim=1)\n",
        "\n",
        "        # RNNRegularizer config:\n",
        "        self.rnn.out = dropped\n",
        "        self.rnn.raw_out = raw\n",
        "\n",
        "        return self.h_o(raw)\n",
        "\n",
        "    def reset(self):\n",
        "        for h in self.h:\n",
        "            h.zero_()"
      ],
      "metadata": {
        "id": "-7-s7DtkgmDG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LSTM_Model(len(vocab), 64, 2, 0.5),\n",
        "    loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "    cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])\n",
        "learn.fit_one_cycle(15, 5e-3, wd=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "d6t4VJ1fkl29",
        "outputId": "46659d8e-1783-4ec1-9d3a-b06b6f1c6a11"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.778816</td>\n",
              "      <td>2.516778</td>\n",
              "      <td>0.375488</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.931565</td>\n",
              "      <td>2.088421</td>\n",
              "      <td>0.338298</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.563989</td>\n",
              "      <td>1.858421</td>\n",
              "      <td>0.396810</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.198632</td>\n",
              "      <td>1.396879</td>\n",
              "      <td>0.565918</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.766268</td>\n",
              "      <td>0.912037</td>\n",
              "      <td>0.719076</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.445010</td>\n",
              "      <td>0.659433</td>\n",
              "      <td>0.815999</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.269486</td>\n",
              "      <td>0.534309</td>\n",
              "      <td>0.865397</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.180512</td>\n",
              "      <td>0.499417</td>\n",
              "      <td>0.874430</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.135877</td>\n",
              "      <td>0.462129</td>\n",
              "      <td>0.883708</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.111229</td>\n",
              "      <td>0.458973</td>\n",
              "      <td>0.883057</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.096981</td>\n",
              "      <td>0.441302</td>\n",
              "      <td>0.890218</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.087585</td>\n",
              "      <td>0.445705</td>\n",
              "      <td>0.882731</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.081946</td>\n",
              "      <td>0.429068</td>\n",
              "      <td>0.891357</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.077855</td>\n",
              "      <td>0.436522</td>\n",
              "      <td>0.888184</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.075671</td>\n",
              "      <td>0.431552</td>\n",
              "      <td>0.890218</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Research 3: GRU architecture\n",
        "Search the internet for the GRU architecture and implement it from scratch, and\n",
        "try training a model. See if you can get results similar to those we saw in this\n",
        "chapter. Compare your results to the results of PyTorch’s built-in GRU module"
      ],
      "metadata": {
        "id": "dMvoKhsqy7XX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first use the built in GRU module"
      ],
      "metadata": {
        "id": "Fs-F1M7BzfGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Torch_GRU(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.GRU(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        raw, self.h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = self.h.detach()\n",
        "\n",
        "        # RNNRegularizer config:\n",
        "        self.rnn.out = out\n",
        "        self.rnn.raw_out = raw\n",
        "\n",
        "        return self.h_o(out)\n",
        "\n",
        "    def reset(self):\n",
        "        self.h.zero_()"
      ],
      "metadata": {
        "id": "w7-45v1mVRzA"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, Torch_GRU(len(vocab), 64, 4, 0.5),\n",
        "    loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "    cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])\n",
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "Eo_bQfSQz1sP",
        "outputId": "18224a1d-0776-4f83-bff4-2f7429767cd9"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.786015</td>\n",
              "      <td>2.150858</td>\n",
              "      <td>0.444824</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.824600</td>\n",
              "      <td>1.333833</td>\n",
              "      <td>0.659993</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.992794</td>\n",
              "      <td>0.741336</td>\n",
              "      <td>0.800863</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.517223</td>\n",
              "      <td>0.528107</td>\n",
              "      <td>0.852051</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.275163</td>\n",
              "      <td>0.403291</td>\n",
              "      <td>0.877930</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.162597</td>\n",
              "      <td>0.318267</td>\n",
              "      <td>0.904948</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.107959</td>\n",
              "      <td>0.274084</td>\n",
              "      <td>0.923991</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.079868</td>\n",
              "      <td>0.327340</td>\n",
              "      <td>0.896077</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.063948</td>\n",
              "      <td>0.266987</td>\n",
              "      <td>0.927002</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.054332</td>\n",
              "      <td>0.292912</td>\n",
              "      <td>0.908040</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.047763</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.939209</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.042366</td>\n",
              "      <td>0.276094</td>\n",
              "      <td>0.919189</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.038869</td>\n",
              "      <td>0.252226</td>\n",
              "      <td>0.930501</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.036600</td>\n",
              "      <td>0.267519</td>\n",
              "      <td>0.922201</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.035324</td>\n",
              "      <td>0.264035</td>\n",
              "      <td>0.925618</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes it is perfoming much better than LSTM (I have got over 95% accuracy a few times), I assume thats because its simpler architecture fits better to this simple task, in a way at least"
      ],
      "metadata": {
        "id": "dcT3ATI9NHKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found out that pytorch implementation of GRU module differs from the cannonical version, therefore I will test both"
      ],
      "metadata": {
        "id": "aOT-tCY0aVJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_Standard(Module):\n",
        "    def __init__(self, i_s, n_hidden, n_layers):\n",
        "        inp = i_s + n_hidden\n",
        "        self.reset = nn.Linear(inp, n_hidden, bias=True)\n",
        "        self.update = nn.Linear(inp, n_hidden, bias=True)\n",
        "        self.outp = nn.Linear(inp, n_hidden, bias=True)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        inp = torch.cat([state, x], dim=1)\n",
        "        u = torch.sigmoid(self.reset(inp)) * state\n",
        "        z = torch.sigmoid(self.update(inp))\n",
        "        inp2 = torch.cat([state, u], dim=1)\n",
        "        ht = self.outp(inp2).tanh()\n",
        "        state = z * state + (1-z) * ht\n",
        "        return state, state"
      ],
      "metadata": {
        "id": "9jfHtKC2ZrFo"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_TorchLike(Module):\n",
        "    def __init__(self, i_s, n_hidden, n_layers):\n",
        "        inp = i_s + n_hidden\n",
        "        self.reset = nn.Linear(inp, n_hidden, bias=True)\n",
        "        self.update = nn.Linear(inp, n_hidden, bias=True)\n",
        "        self.outx = nn.Linear(i_s, n_hidden, bias=True)\n",
        "        self.outs = nn.Linear(n_hidden, n_hidden, bias=True)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        inp = torch.cat([state, x], dim=1)\n",
        "        r = torch.sigmoid(self.reset(inp))\n",
        "        z = torch.sigmoid(self.update(inp))\n",
        "        ht = (self.outx(x) + r * self.outs(state)).tanh()\n",
        "        state = z * state + (1-z) * ht\n",
        "        return state, state"
      ],
      "metadata": {
        "id": "u-PxdFfwNOfO"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_Model(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.n_layers = n_layers\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = GRU_TorchLike(n_hidden, n_hidden, n_layers)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h = [torch.zeros(bs, n_hidden) for _ in range(n_layers)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        raw = []\n",
        "        dropped = []\n",
        "        for i in range(sl):\n",
        "            for j in range(self.n_layers):\n",
        "                y, self.h[j] = self.rnn(self.i_h(x[:, i]), self.h[j])\n",
        "\n",
        "            raw.append(y)\n",
        "            y = self.drop(y)\n",
        "            dropped.append(y)\n",
        "\n",
        "        raw = torch.stack(raw, dim=1)\n",
        "        dropped = torch.stack(dropped, dim=1)\n",
        "        self.h = [h.detach() for h in self.h]\n",
        "\n",
        "        # RNNRegularizer config:\n",
        "        self.rnn.out = dropped\n",
        "        self.rnn.raw_out = raw\n",
        "\n",
        "        return self.h_o(dropped)\n",
        "\n",
        "    def reset(self):\n",
        "        for h in self.h:\n",
        "            h.zero_()"
      ],
      "metadata": {
        "id": "Bmng_sRTUyKX"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, GRU_Model(len(vocab), 64, 4, 0.5),\n",
        "    loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "    cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])\n",
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "AziVARSwZLmS",
        "outputId": "cfa0065c-427c-424e-a9c8-72e7fead3ba4"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.866516</td>\n",
              "      <td>2.546429</td>\n",
              "      <td>0.280518</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.483351</td>\n",
              "      <td>2.016129</td>\n",
              "      <td>0.375651</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.869330</td>\n",
              "      <td>1.471062</td>\n",
              "      <td>0.553874</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.338608</td>\n",
              "      <td>1.128061</td>\n",
              "      <td>0.651123</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.961023</td>\n",
              "      <td>0.877481</td>\n",
              "      <td>0.726318</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.717956</td>\n",
              "      <td>0.675056</td>\n",
              "      <td>0.802897</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.553062</td>\n",
              "      <td>0.615733</td>\n",
              "      <td>0.812419</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.447666</td>\n",
              "      <td>0.513644</td>\n",
              "      <td>0.869222</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.376951</td>\n",
              "      <td>0.467945</td>\n",
              "      <td>0.891357</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.328746</td>\n",
              "      <td>0.399597</td>\n",
              "      <td>0.921143</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.294728</td>\n",
              "      <td>0.381414</td>\n",
              "      <td>0.929606</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.265160</td>\n",
              "      <td>0.369545</td>\n",
              "      <td>0.933350</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.242719</td>\n",
              "      <td>0.349106</td>\n",
              "      <td>0.938314</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.228711</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.933024</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.219545</td>\n",
              "      <td>0.346474</td>\n",
              "      <td>0.939128</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TorchLike version of the module seems to perform better here, although because pytorch built-in implementation initializes weights better than me, my implementatations usually ends up with much worse results, and to be honest the result above is kinda a miracle :P usually I was getting 88% accuracy"
      ],
      "metadata": {
        "id": "Ocq429b-dlXT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8_R-FlMPrUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}