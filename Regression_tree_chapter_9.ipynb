{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "6sps5N01HFzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq opendatasets"
      ],
      "metadata": {
        "id": "G6LBGWFOLmSc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YhzgieiQHYtE"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/c/bluebook-for-bulldozers/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9vC-fg6Hut9",
        "outputId": "16bc85ca-f91f-4b01-b64b-cada5d908e47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: nonscop\n",
            "Your Kaggle Key: ··········\n",
            "Downloading bluebook-for-bulldozers.zip to ./bluebook-for-bulldozers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48.4M/48.4M [00:02<00:00, 22.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./bluebook-for-bulldozers/bluebook-for-bulldozers.zip to ./bluebook-for-bulldozers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path(\"bluebook-for-bulldozers\")"
      ],
      "metadata": {
        "id": "mfImf_dLIjLm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in path.iterdir():\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_dh7RoxJb_W",
        "outputId": "b81d03d7-8b82-4ef0-d168-aeab274e5f5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bluebook-for-bulldozers/TrainAndValid.csv\n",
            "bluebook-for-bulldozers/Train.7z\n",
            "bluebook-for-bulldozers/Machine_Appendix.csv\n",
            "bluebook-for-bulldozers/Data Dictionary.xlsx\n",
            "bluebook-for-bulldozers/Train.zip\n",
            "bluebook-for-bulldozers/median_benchmark.csv\n",
            "bluebook-for-bulldozers/random_forest_benchmark_test.csv\n",
            "bluebook-for-bulldozers/ValidSolution.csv\n",
            "bluebook-for-bulldozers/Test.csv\n",
            "bluebook-for-bulldozers/TrainAndValid.zip\n",
            "bluebook-for-bulldozers/Valid.csv\n",
            "bluebook-for-bulldozers/Valid.zip\n",
            "bluebook-for-bulldozers/TrainAndValid.7z\n",
            "bluebook-for-bulldozers/Valid.7z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path/'TrainAndValid.csv', low_memory=False)\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYgqloAVKHCl",
        "outputId": "51dba2ea-aa7d-4842-d779-b473a0de7196"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SalesID', 'SalePrice', 'MachineID', 'ModelID', 'datasource',\n",
              "       'auctioneerID', 'YearMade', 'MachineHoursCurrentMeter', 'UsageBand',\n",
              "       'saledate', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc',\n",
              "       'fiModelSeries', 'fiModelDescriptor', 'ProductSize',\n",
              "       'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc',\n",
              "       'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control',\n",
              "       'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension',\n",
              "       'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics',\n",
              "       'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size',\n",
              "       'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow',\n",
              "       'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb',\n",
              "       'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type',\n",
              "       'Travel_Controls', 'Differential_Type', 'Steering_Controls'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['ProductSize'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8VgRCfcKJew",
        "outputId": "73ad3bd8-6ee2-45d4-feca-6f3940154eef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'Medium', 'Small', 'Large / Medium', 'Mini', 'Large',\n",
              "       'Compact'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = 'Large','Large / Medium','Medium','Small','Mini','Compact'\n",
        "df['ProductSize'] = df['ProductSize'].astype('category')\n",
        "df['ProductSize'] = df['ProductSize'].cat.set_categories(sizes, ordered=True)"
      ],
      "metadata": {
        "id": "wTgYd2CWLDBs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dep_var = 'SalePrice'\n",
        "df[dep_var] = np.log(df[dep_var])"
      ],
      "metadata": {
        "id": "_VnRd2O6LICY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = add_datepart(df, 'saledate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXnkWbr2LVTf",
        "outputId": "04f8dee1-36a4-4c22-9ac4-ac9e992f65cd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/tabular/core.py:23: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(path/'Test.csv', low_memory=False)\n",
        "df_test = add_datepart(df_test, 'saledate')\n",
        "' '.join(o for o in df.columns if o.startswith('sale'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "vJdpEGaULvjb",
        "outputId": "cd756034-d7ca-425f-f316-16b42b862423"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/tabular/core.py:23: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'saleYear saleMonth saleWeek saleDay saleDayofweek saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "procs = [Categorify, FillMissing]"
      ],
      "metadata": {
        "id": "_vCOVhFeLz2N"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond = (df.saleYear<2011) | (df.saleMonth<10)\n",
        "train_idx = np.where( cond)[0]\n",
        "valid_idx = np.where(~cond)[0]\n",
        "\n",
        "splits = (list(train_idx),list(valid_idx))\n",
        "cont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n",
        "to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL4deMJ3MDkC",
        "outputId": "4d451e51-04e5-4b9d-e3a1-ce31470e325c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  to[n].fillna(self.na_dict[n], inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  to[n].fillna(self.na_dict[n], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cont"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-6kown3P5eT",
        "outputId": "c59d9a7f-794f-45fb-d4e2-0f21cf8d2175"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SalesID',\n",
              " 'MachineID',\n",
              " 'ModelID',\n",
              " 'datasource',\n",
              " 'auctioneerID',\n",
              " 'YearMade',\n",
              " 'MachineHoursCurrentMeter',\n",
              " 'saleYear',\n",
              " 'saleMonth',\n",
              " 'saleWeek',\n",
              " 'saleDay',\n",
              " 'saleDayofweek',\n",
              " 'saleDayofyear',\n",
              " 'saleElapsed']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression decision tree implementation from scratch"
      ],
      "metadata": {
        "id": "MNBSLai5HMRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to = load_pickle('to.pkl')"
      ],
      "metadata": {
        "id": "G2699bDQM4o2"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs,y = to.train.xs,to.train.y\n",
        "valid_xs,valid_y = to.valid.xs,to.valid.y"
      ],
      "metadata": {
        "id": "L4HoufDeMQoC"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\n",
        "def m_rmse(m, xs, y): return r_mse(m.predict(xs), y)"
      ],
      "metadata": {
        "id": "xTR7JPgdOXgt"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the results of sklearn tree for comparison"
      ],
      "metadata": {
        "id": "GTOxDWXtHWRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = DecisionTreeRegressor(min_samples_leaf=25, max_leaf_nodes=16)\n",
        "m.fit(to.train.xs.head(1000), to.train.y.head(1000))\n",
        "m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flI1eUxvSiJR",
        "outputId": "317ee3e6-f932-4bc0-9b9e-457de4969bc0"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.547378, 0.513194)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, columns, xs, y, min_samples_leaf):\n",
        "        self.columns = columns\n",
        "        self.avg = y[xs.index].mean()\n",
        "        self.xs = xs\n",
        "        self.y = y[xs.index]\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.split_col = None\n",
        "        self.threshold = None\n",
        "        self.childl = None\n",
        "        self.childr = None\n",
        "\n",
        "\n",
        "    def gain(self, xl, xr, column):\n",
        "        pl = len(xl) / len(self.xs)\n",
        "        pr = len(xr) / len(self.xs)\n",
        "        return np.var(self.y) - pr * np.var(self.y[xr.index]) - pl * np.var(self.y[xl.index])\n",
        "\n",
        "\n",
        "    def split(self):\n",
        "        best = [0]\n",
        "        for column in self.xs.columns:\n",
        "            for tresh in self.xs[column].unique():\n",
        "                xl = self.xs[self.xs[column] <= tresh]\n",
        "                xr = self.xs[self.xs[column] > tresh]\n",
        "                score = self.gain(xl, xr, column)\n",
        "                if score > best[0] and len(xl) >= self.min_samples_leaf and len(xr) >= self.min_samples_leaf:\n",
        "                    best = [score, column, tresh]\n",
        "\n",
        "        if len(best) == 1:\n",
        "            return [0,0,0,0]\n",
        "\n",
        "        self.split_col = best[1]\n",
        "        self.threshold = best[2]\n",
        "\n",
        "        xl = self.xs[self.xs[best[1]] <= best[2]]\n",
        "        xr = self.xs[self.xs[best[1]] > best[2]]\n",
        "        self.childl = Node(self.columns, xl, self.y, self.min_samples_leaf)\n",
        "        self.childr = Node(self.columns, xr, self.y, self.min_samples_leaf)\n",
        "        return [self.childl, self.childr]\n",
        "\n",
        "\n",
        "    def predict_row(self, x):\n",
        "        if self.split_col == None:\n",
        "            return self.avg\n",
        "        elif x[self.split_col] <= self.threshold:\n",
        "            return self.childl.predict_row(x)\n",
        "        else:\n",
        "            return self.childr.predict_row(x)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "f6a_-53hOjHX"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegressionTree:\n",
        "    def __init__(self, min_samples_leaf=1, max_leaf_nodes=float('inf')):\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_leaf_nodes = max_leaf_nodes\n",
        "        self.root = None\n",
        "        self.num_of_leaves = 1\n",
        "\n",
        "\n",
        "    def fit(self, xs, y):\n",
        "        self.root = Node(xs.columns, xs, y, self.min_samples_leaf)\n",
        "        leaves = [self.root]\n",
        "        while self.num_of_leaves < self.max_leaf_nodes:\n",
        "            leaf = leaves.pop(0)\n",
        "            childs = leaf.split()\n",
        "            self.num_of_leaves += 1\n",
        "            if len(childs) == 4:\n",
        "                return 0\n",
        "\n",
        "            leaves.extend(childs)\n",
        "\n",
        "\n",
        "    def predict(self, xs):\n",
        "        out = []\n",
        "        for _, x in xs.iterrows():\n",
        "            out.append(self.root.predict_row(x))\n",
        "\n",
        "        return np.array(out)\n"
      ],
      "metadata": {
        "id": "uIoNPsS4M7CU"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = RegressionTree(min_samples_leaf=25, max_leaf_nodes=16)\n",
        "m.fit(to.train.xs.head(1000), to.train.y.head(1000))\n",
        "m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRAyOxweOgYf",
        "outputId": "5fecd13a-4f5c-47e9-e317-d06be65a4f28"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.55087, 0.546175)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "quite ok result, the main drawback of my tree is how slow it trains and predicts, therefore it is practically useless for larger datasets, for the time I am doing this I don't know how to make it more efficient in python."
      ],
      "metadata": {
        "id": "XbMq0JxNHjtQ"
      }
    }
  ]
}